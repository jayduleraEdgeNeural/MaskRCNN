

num_classes: 21
epochs: 1
batch_size: 16
num_workers: 2

#params: [p for p in model.parameters() if p.requires_grad]
#optimizer: torch.optim.SGD(params, lr=0.005,
#                            momentum=0.9, weight_decay=0.0005)
#
#lr_scheduler: torch.optim.lr_scheduler.StepLR(optimizer,
#                                               step_size=3,
#                                               gamma=0.1)
#Optimizer
lr: 0.005
momentum: 0.9
weight_decay: 0.0005
#LR_Scheduler
step_size: 3
gamma: 0.1
dataset_path: '/'
test_dataset_path: '/'